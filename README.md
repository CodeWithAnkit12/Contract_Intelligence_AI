ğŸ“„ Contract Intelligence API

AI Developer Assignment â€“ Aviara Labs

An AI-powered backend system that ingests legal contracts (PDFs), extracts structured data, answers questions using Retrieval-Augmented Generation (RAG), audits risky clauses, and streams responses â€” all running locally via Docker.

ğŸš€ Overview

Legal contracts are unstructured and difficult to analyze programmatically. This project demonstrates how Generative AI + backend engineering can be combined to:

Ingest and process contract PDFs

Extract structured legal metadata

Answer user questions grounded strictly in uploaded documents

Detect risky clauses with severity and evidence

Stream LLM responses in real time

Provide production-style observability (health & metrics)

The system is designed with clean architecture, explainability, and scalability in mind.

ğŸ§  Key Features
1ï¸âƒ£ PDF Ingestion

Upload one or more PDF contracts

Automatic text extraction

UUID-based document IDs

Chunked and indexed for semantic search

2ï¸âƒ£ Structured Contract Extraction

Extracts the following fields as strict JSON:

Parties

Effective date

Term

Governing law

Payment terms

Termination

Auto-renewal

Confidentiality

Indemnity

Liability cap (amount + currency)

Signatories (name, title)

Missing fields are returned as null.

3ï¸âƒ£ RAG-based Question Answering

Uses vector similarity search over uploaded contracts

LLM answers are grounded only in retrieved context

Returns answers with citations (document IDs)

Prevents hallucination

4ï¸âƒ£ Clause Risk Audit

Detects risky clauses such as:

Auto-renewal with short notice

Unlimited liability

Broad indemnity

Missing termination rights

Each finding includes:

Risk description

Severity (LOW / MEDIUM / HIGH)

Evidence snippet

5ï¸âƒ£ Streaming Responses (SSE)

Token-by-token streaming for /ask/stream

Improves perceived latency

Excellent demo UX

6ï¸âƒ£ Mini UI (Bonus UX)

Minimal Tailwind-based UI

Ask questions and see streamed answers

Served directly by FastAPI (no frontend build required)

7ï¸âƒ£ Production Signals

/healthz readiness endpoint

/metrics Prometheus-compatible metrics

Clean logging

Dockerized setup

ğŸ—ï¸ Architecture
Client (Swagger / Mini UI)
        â†“
FastAPI Application
        â†“
PDF Parsing & Chunking
        â†“
Vector Store (ChromaDB)
        â†“
LLM (Extraction / RAG / Audit)

ğŸ› ï¸ Tech Stack

Backend

Python 3.11

FastAPI

Uvicorn

AI / GenAI

OpenAI GPT-4o-mini

OpenAI Embeddings (text-embedding-3-small)

Prompt-driven extraction & auditing

Vector Store

ChromaDB (local)

PDF Processing

PyPDF

Observability

Prometheus client

Infra

Docker

Docker Compose

ğŸ“ Project Structure
contract-intelligence-ai/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/            # API routes
â”‚   â”œâ”€â”€ core/           # LLM & config
â”‚   â”œâ”€â”€ services/       # Business logic
â”‚   â”œâ”€â”€ utils/          # Helpers (chunking)
â”‚   â”œâ”€â”€ prompts/        # LLM prompts (verbatim)
â”‚   â””â”€â”€ eval/           # Evaluation scripts
â”‚
â”œâ”€â”€ ui/                 # Mini UI
â”œâ”€â”€ data/               # PDFs & vector data
â”œâ”€â”€ tests/              # Tests
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md

âš™ï¸ Setup & Installation
1ï¸âƒ£ Clone the repository
git clone <your-repo-url>
cd contract-intelligence-ai

2ï¸âƒ£ Create .env
OPENAI_API_KEY=your_api_key_here
MODEL_NAME=gpt-4o-mini


âš ï¸ Do not commit .env

3ï¸âƒ£ Run with Docker (recommended)
docker compose up --build


The API will be available at:

API: http://localhost:8000

Swagger Docs: http://localhost:8000/docs

Mini UI: http://localhost:8000/

ğŸ”Œ API Endpoints
ğŸ”¹ Ingest

POST /ingest

Upload one or more PDFs.

Response

{
  "document_ids": ["uuid-1", "uuid-2"]
}

ğŸ”¹ Extract

POST /extract/{document_id}

Returns structured JSON fields extracted from the contract.

ğŸ”¹ Ask (RAG)

POST /ask

{
  "question": "What is the liability cap?"
}


Response

{
  "answer": "...",
  "citations": [{ "doc_id": "uuid" }]
}

ğŸ”¹ Ask (Streaming)

POST /ask/stream

Streams tokens via Server-Sent Events (SSE).

ğŸ”¹ Audit

POST /audit/{document_id}

Returns detected risky clauses with severity and evidence.

ğŸ”¹ Health & Metrics

GET /healthz

GET /metrics

ğŸ§ª Tests

Run tests locally:

pytest


Includes basic API health validation.

ğŸ“Š Evaluation

The app/eval/ folder contains:

Sample Q&A pairs

Simple evaluation script

One-line accuracy summary

Used to sanity-check RAG answer quality.

ğŸ§© Design Decisions & Trade-offs

FastAPI over Django â†’ async, AI-friendly, better streaming

RAG over fine-tuning â†’ safer, cheaper, explainable

ChromaDB (local) â†’ simplicity for assignment, easy migration later

Prompt discipline â†’ reproducibility & transparency

Minimal UI â†’ demo-focused, reviewer-friendly

ğŸ” Security Notes

API keys stored only in environment variables

No training on user-uploaded data

RAG restricts LLM answers to provided context

Logs avoid raw contract content

ğŸ”® Future Improvements

Background task processing

Authentication & authorization

Page-level citations

Managed vector DB (Pinecone)

Async ingestion workers

Rule-based audit fallback toggle

ğŸ¥ Loom Demo

A Loom walkthrough (8â€“10 minutes) is provided demonstrating:

Docker startup

Swagger docs

PDF ingestion

Extraction

RAG Q&A

Clause audit

Streaming

Metrics & tests

ğŸ‘¤ Author

Ankit Kumar
Backend / AI Engineer
Python â€¢ FastAPI â€¢ GenAI â€¢ RAG